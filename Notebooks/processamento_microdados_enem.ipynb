{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "339b1583-ef73-40a5-9735-354b42f393b5",
   "metadata": {},
   "source": [
    "## Importação das Bibiliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc20c5a9-44d0-4ee3-ac2c-0f588099a1c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from pyspark.sql.functions import col, count, sum\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType, StructType, StructField, LongType\n",
    "import pymssql\n",
    "#import pyodbc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92050d4",
   "metadata": {},
   "source": [
    "## Criando uma SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "137c301b-7b56-434b-bd08-979c6717af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando a Imagem Docker\n",
    "#spark = SparkSession.builder.remote(\"sc://spark-connect\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d05b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie um SparkSession\n",
    "spark = SparkSession.builder.appName(\"LerDadosEnem\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8ed9e6-77de-42fb-96ed-d1b23d0251a4",
   "metadata": {},
   "source": [
    "## Processo de Leitura dos arquivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c848f5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path dos arquivos usando Imagem do docker\n",
    "\n",
    "#caminho_arquivo_2022 = '/opt/datasets/ENEM/2022/microdados_enem_2022/DADOS/MICRODADOS_ENEM_2022.csv'\n",
    "#caminho_arquivo_2021 = '/opt/datasets/ENEM/2021/microdados_enem_2021/DADOS/MICRODADOS_ENEM_2021.csv'\n",
    "#caminho_arquivo_2020 = '/opt/datasets/ENEM/2020/microdados_enem_2020/DADOS/MICRODADOS_ENEM_2020.csv'\n",
    "#caminho_arquivo_2019 = '/opt/datasets/ENEM/2019/microdados_enem_2019/DADOS/MICRODADOS_ENEM_2019.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce135fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path dos arquivos\n",
    "\n",
    "caminho_arquivo_2022 = r'E:\\Estudos\\SQL\\Datasets\\ENEM\\2022\\microdados_enem_2022\\DADOS\\MICRODADOS_ENEM_2022.csv'\n",
    "caminho_arquivo_2021 = r'E:\\Estudos\\SQL\\Datasets\\ENEM\\2021\\microdados_enem_2021\\DADOS\\MICRODADOS_ENEM_2021.csv'\n",
    "caminho_arquivo_2020 = r'E:\\Estudos\\SQL\\Datasets\\ENEM\\2020\\microdados_enem_2020\\DADOS\\MICRODADOS_ENEM_2020.csv'\n",
    "caminho_arquivo_2019 = r'E:\\Estudos\\SQL\\Datasets\\ENEM\\2019\\microdados_enem_2019\\DADOS\\MICRODADOS_ENEM_2019.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04836a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função Paa ler os arquivos CSV\n",
    "def lerCSV(spark, caminho_arquivo):\n",
    "    df = spark.read.csv(caminho_arquivo, sep=';', header=True, inferSchema=True, encoding='UTF-8')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6b4735",
   "metadata": {},
   "source": [
    "## Criação dos Dataframes e Unificaçao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "158e76e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Chama função quer ler o arquivo CSV e Transforma para DF.SPARK\n",
    "\n",
    "dfEscola22 = lerCSV(spark, caminho_arquivo_2022)\n",
    "dfEscola21 = lerCSV(spark, caminho_arquivo_2021)\n",
    "dfEscola20 = lerCSV(spark, caminho_arquivo_2020)\n",
    "dfEscola19 = lerCSV(spark, caminho_arquivo_2019)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "579583cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unir os DF em um só \n",
    "\n",
    "dfDadosGerais = dfEscola22.union(dfEscola21).union(dfEscola20).union(dfEscola19)\n",
    "#dfDadosGerais = dfEscola22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0ddb3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPreencher = dfDadosGerais.fillna(-2)  # Preenche com -2(sem ref), por exemplo\n",
    "#dfPreencher.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff1067c",
   "metadata": {},
   "source": [
    "## Criação das Dimes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf7f58d",
   "metadata": {},
   "source": [
    "### Dime Municipios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c06fe582-dbdc-439b-be2c-707748b304a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfDimeMunicipio = dfPreencher.select(\n",
    "    col(\"CO_MUNICIPIO_ESC\").alias(\"MUNICIPIO_ID\"),\n",
    "    col(\"NO_MUNICIPIO_ESC\").alias(\"MUNICIPIO_DESCRICAO\"),\n",
    "    col(\"CO_UF_ESC\").alias(\"UF_ID\")\n",
    ").distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a30c8b",
   "metadata": {},
   "source": [
    "### Dime UF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dbf3896",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUF = dfPreencher.select(\n",
    "    col(\"CO_UF_ESC\").alias(\"UF_ID\"),\n",
    "    col(\"SG_UF_ESC\").alias(\"UF_SIGLA\")\n",
    ").distinct()\n",
    "\n",
    "dfUF.createOrReplaceTempView(\"TEMP_UF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631e9216",
   "metadata": {},
   "source": [
    "### Dicionário de Siglas UF dos Estados Brasileiros e sua descrição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1926dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDimeUF = spark.sql(\"\"\"\n",
    "        SELECT T.*,A.UF_DESCRICAO FROM(\n",
    "        SELECT 'RO' AS UF_ID, 'Rondônia' AS UF_DESCRICAO\n",
    "        UNION ALL\n",
    "        SELECT 'AC', 'Acre'\n",
    "        UNION ALL\n",
    "        SELECT 'AM', 'Amazonas'\n",
    "        UNION ALL\n",
    "        SELECT 'RR', 'Roraima'\n",
    "        UNION ALL\n",
    "        SELECT 'PA', 'Pará'\n",
    "        UNION ALL\n",
    "        SELECT 'AP', 'Amapá'\n",
    "        UNION ALL\n",
    "        SELECT 'TO', 'Tocantins'\n",
    "        UNION ALL\n",
    "        SELECT 'MA', 'Maranhão'\n",
    "        UNION ALL\n",
    "        SELECT 'PI', 'Piauí'\n",
    "        UNION ALL\n",
    "        SELECT 'CE', 'Ceará'\n",
    "        UNION ALL\n",
    "        SELECT 'RN', 'Rio Grande do Norte'\n",
    "        UNION ALL\n",
    "        SELECT 'PB', 'Paraíba'\n",
    "        UNION ALL\n",
    "        SELECT 'PE', 'Pernambuco'\n",
    "        UNION ALL\n",
    "        SELECT 'AL', 'Alagoas'\n",
    "        UNION ALL\n",
    "        SELECT 'SE', 'Sergipe'\n",
    "        UNION ALL\n",
    "        SELECT 'BA', 'Bahia'\n",
    "        UNION ALL\n",
    "        SELECT 'MG', 'Minas Gerais'\n",
    "        UNION ALL\n",
    "        SELECT 'ES', 'Espírito Santo'\n",
    "        UNION ALL\n",
    "        SELECT 'RJ', 'Rio de Janeiro'\n",
    "        UNION ALL\n",
    "        SELECT 'SP', 'São Paulo'\n",
    "        UNION ALL\n",
    "        SELECT 'PR', 'Paraná'\n",
    "        UNION ALL\n",
    "        SELECT 'SC', 'Santa Catarina'\n",
    "        UNION ALL\n",
    "        SELECT 'RS', 'Rio Grande do Sul'\n",
    "        UNION ALL\n",
    "        SELECT 'MS', 'Mato Grosso do Sul'\n",
    "        UNION ALL\n",
    "        SELECT 'MT', 'Mato Grosso'\n",
    "        UNION ALL\n",
    "        SELECT 'GO', 'Goiás'\n",
    "        UNION ALL\n",
    "        SELECT 'DF', 'Distrito Federal'\n",
    "        UNION ALL\n",
    "        SELECT '-2', 'Sem Referência') A\n",
    "        INNER JOIN TEMP_UF T\n",
    "        ON A.UF_ID = T.UF_SIGLA\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "222f8bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimeManualCorRacao = r'C:\\Users\\leoba\\Documents\\Enem\\Dataset\\Dimes\\Dime_Cor_Raca.csv'\n",
    "dimeManualEscola = r'C:\\Users\\leoba\\Documents\\Enem\\Dataset\\Dimes\\Dime_Escola.csv'\n",
    "dimeManualEstadoCivil = r'C:\\Users\\leoba\\Documents\\Enem\\Dataset\\Dimes\\Dime_Estado_Civil.csv'\n",
    "dimeManualFaixaEtaria = r'C:\\Users\\leoba\\Documents\\Enem\\Dataset\\Dimes\\Dime_Faixa_Etaria.csv'\n",
    "dimeManualFaixaRendaMensal = r'C:\\Users\\leoba\\Documents\\Enem\\Dataset\\Dimes\\Dime_Faixa_Renda_Mensal.csv'\n",
    "dimeManualNacionalidade = r'C:\\Users\\leoba\\Documents\\Enem\\Dataset\\Dimes\\Dime_Nacionalidade.csv'\n",
    "dimeManualSexo = r'C:\\Users\\leoba\\Documents\\Enem\\Dataset\\Dimes\\Dime_Sexo.csv'\n",
    "dimeManualSituacaoEscolaridade = r'C:\\Users\\leoba\\Documents\\Enem\\Dataset\\Dimes\\Dime_Situacao_Escolaridade.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d79c1781",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Chama função quer ler o arquivo CSV e Transforma para DF.SPARK\n",
    "dfDimeCorRaca = lerCSV(spark, dimeManualCorRacao)\n",
    "dfDimeEscola = lerCSV(spark, dimeManualEscola)\n",
    "dfDimeEstadoCivil = lerCSV(spark,dimeManualEstadoCivil)\n",
    "dfDimeFaixaEtaria = lerCSV(spark,dimeManualFaixaEtaria)\n",
    "dfDimeFaixaRendaMensal = lerCSV(spark,dimeManualFaixaRendaMensal)\n",
    "dfDimeNacionalidade = lerCSV(spark,dimeManualNacionalidade)\n",
    "dfDimeSexo = lerCSV(spark,dimeManualSexo)\n",
    "dfDimeSituacaoEscolaridade = lerCSV(spark,dimeManualSituacaoEscolaridade)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffea102",
   "metadata": {},
   "source": [
    "## Criação da Fato Enem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b839ff03-3177-4106-9812-c704694c2b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPreencherDistinct = dfPreencher.select(\n",
    "    col(\"NU_INSCRICAO\").alias(\"NU_INSCRICAO\"),\n",
    "    col(\"NU_ANO\").alias(\"ANO_EDICAO\"),\n",
    "    col(\"TP_ANO_CONCLUIU\").alias(\"ANO_CONCLUSAO\"),\n",
    "    col(\"TP_SEXO\").alias(\"SEXO_ID\"),\n",
    "    col(\"CO_MUNICIPIO_ESC\").alias(\"MUNICIPIO_ID\"),\n",
    "    col(\"TP_ESTADO_CIVIL\").alias(\"ESTADO_CIVIL_ID\"),\n",
    "    col(\"TP_COR_RACA\").alias(\"COR_RACA_ID\"),\n",
    "    col(\"TP_NACIONALIDADE\").alias(\"NACIONALIDADE_ID\"),\n",
    "    col(\"TP_ST_CONCLUSAO\").alias(\"SITUACAO_ESCOLARIDADE_ID\"),\n",
    "    col(\"TP_ESCOLA\").alias(\"ESCOLA_ID\"),\n",
    "    col(\"Q006\").alias(\"FAIXA_RENDA_MENSAL_ID\"),\n",
    "    col(\"TP_FAIXA_ETARIA\").alias(\"FAIXA_ETARIA_ID\"),\n",
    "    col(\"NU_NOTA_CN\").alias(\"NOTA_CIENCIA_DA_NATUREZA\"),\n",
    "    col(\"NU_NOTA_CH\").alias(\"NOTA_CIENCIA_DA_HUMANA\"),\n",
    "    col(\"NU_NOTA_LC\").alias(\"NOTA_LINGUAGEM_CODIGO\"),\n",
    "    col(\"NU_NOTA_MT\").alias(\"NOTA_MATEMATICA\")\n",
    ").distinct()\n",
    "#dfPreencherDistinct.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a8852d0-721d-41a7-a6f9-366cd5d2c6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ANO_EDICAO: int, ANO_CONCLUSAO: int, SEXO_ID: string, MUNICIPIO_ID: int, ESTADO_CIVIL_ID: int, COR_RACA_ID: int, NACIONALIDADE_ID: int, SITUACAO_ESCOLARIDADE_ID: int, ESCOLA_ID: int, FAIXA_RENDA_MENSAL_ID: string, FAIXA_ETARIA_ID: int, QTD: bigint, NOTA_CIENCIA_DA_NATUREZA: double, NOTA_CIENCIA_DA_HUMANA: double, NOTA_LINGUAGEM_CODIGO: double, NOTA_MATEMATICA: double]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAgregate = dfPreencherDistinct.select(\n",
    "    \"ANO_EDICAO\",\n",
    "    \"ANO_CONCLUSAO\",\n",
    "    \"SEXO_ID\",\n",
    "    \"MUNICIPIO_ID\",\n",
    "    \"ESTADO_CIVIL_ID\",\n",
    "    \"COR_RACA_ID\",\n",
    "    \"NACIONALIDADE_ID\",\n",
    "    \"SITUACAO_ESCOLARIDADE_ID\",\n",
    "    \"ESCOLA_ID\",\n",
    "    \"FAIXA_RENDA_MENSAL_ID\",\n",
    "    \"FAIXA_ETARIA_ID\",\n",
    "    \"NU_INSCRICAO\",  # Adicionando essa coluna para o count\n",
    "    \"NOTA_CIENCIA_DA_NATUREZA\",\n",
    "    \"NOTA_CIENCIA_DA_HUMANA\",\n",
    "    \"NOTA_LINGUAGEM_CODIGO\",\n",
    "    \"NOTA_MATEMATICA\"\n",
    ")\n",
    "\n",
    "# Agregação após o agrupamento\n",
    "dfAgregate = dfAgregate.groupBy(\n",
    "    \"ANO_EDICAO\",\n",
    "    \"ANO_CONCLUSAO\",\n",
    "    \"SEXO_ID\",\n",
    "    \"MUNICIPIO_ID\",\n",
    "    \"ESTADO_CIVIL_ID\",\n",
    "    \"COR_RACA_ID\",\n",
    "    \"NACIONALIDADE_ID\",\n",
    "    \"SITUACAO_ESCOLARIDADE_ID\",\n",
    "    \"ESCOLA_ID\",\n",
    "    \"FAIXA_RENDA_MENSAL_ID\",\n",
    "    \"FAIXA_ETARIA_ID\"\n",
    ").agg(\n",
    "    count(\"NU_INSCRICAO\").alias(\"QTD\"),\n",
    "    sum(\"NOTA_CIENCIA_DA_NATUREZA\").alias(\"NOTA_CIENCIA_DA_NATUREZA\"),\n",
    "    sum(\"NOTA_CIENCIA_DA_HUMANA\").alias(\"NOTA_CIENCIA_DA_HUMANA\"),\n",
    "    sum(\"NOTA_LINGUAGEM_CODIGO\").alias(\"NOTA_LINGUAGEM_CODIGO\"),\n",
    "    sum(\"NOTA_MATEMATICA\").alias(\"NOTA_MATEMATICA\")\n",
    ")\n",
    "\n",
    "dfAgregate.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69ea3d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAgregate = dfAgregate.withColumn(\"NOTA_CIENCIA_DA_NATUREZA\", col(\"NOTA_CIENCIA_DA_NATUREZA\").cast(DoubleType())) \\\n",
    "                       .withColumn(\"NOTA_CIENCIA_DA_HUMANA\", col(\"NOTA_CIENCIA_DA_HUMANA\").cast(DoubleType())) \\\n",
    "                       .withColumn(\"NOTA_LINGUAGEM_CODIGO\", col(\"NOTA_LINGUAGEM_CODIGO\").cast(DoubleType())) \\\n",
    "                       .withColumn(\"NOTA_MATEMATICA\", col(\"NOTA_MATEMATICA\").cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fc1c05e-073b-4a3d-beeb-7ef9eb6b2f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('ANO_EDICAO', IntegerType(), True), StructField('ANO_CONCLUSAO', IntegerType(), True), StructField('SEXO_ID', StringType(), True), StructField('MUNICIPIO_ID', IntegerType(), True), StructField('ESTADO_CIVIL_ID', IntegerType(), True), StructField('COR_RACA_ID', IntegerType(), True), StructField('NACIONALIDADE_ID', IntegerType(), True), StructField('SITUACAO_ESCOLARIDADE_ID', IntegerType(), True), StructField('ESCOLA_ID', IntegerType(), True), StructField('FAIXA_RENDA_MENSAL_ID', StringType(), True), StructField('FAIXA_ETARIA_ID', IntegerType(), True), StructField('QTD', LongType(), False), StructField('NOTA_CIENCIA_DA_NATUREZA', DoubleType(), True), StructField('NOTA_CIENCIA_DA_HUMANA', DoubleType(), True), StructField('NOTA_LINGUAGEM_CODIGO', DoubleType(), True), StructField('NOTA_MATEMATICA', DoubleType(), True)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAgregate.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ed5ca",
   "metadata": {},
   "source": [
    "# Salvar em SQL \n",
    "Salvar os dados em uma tabela SQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1deb1f",
   "metadata": {},
   "source": [
    "## Parametrizando a conexão do Banco SQL SERVER Usando JDBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e7396db",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_name = \"localhost\"\n",
    "database_name = \"DockerEnem\"\n",
    "username = \"sa\"\n",
    "password = \"bi@123456\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45262d43",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pymssql' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Conectando ao banco de dados\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43mpymssql\u001b[49m\u001b[38;5;241m.\u001b[39mconnect(server\u001b[38;5;241m=\u001b[39mserver_name, database\u001b[38;5;241m=\u001b[39mdatabase_name, user\u001b[38;5;241m=\u001b[39musername, password\u001b[38;5;241m=\u001b[39mpassword,port\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1434\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Criando um cursor\u001b[39;00m\n\u001b[0;32m      4\u001b[0m cursor \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pymssql' is not defined"
     ]
    }
   ],
   "source": [
    "# Conectando ao banco de dados\n",
    "conn = pymssql.connect(server=server_name, database=database_name, user=username, password=password,port='1434')\n",
    "# Criando um cursor\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f250a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicionarioDataFrames = {\n",
    "    \"FATO_ENEM\": dfAgregate,\n",
    "    \"DIME_SEXO\": dfDimeSexo,\n",
    "    \"DIME_MUNICIPIO\": dfDimeMunicipio,\n",
    "    \"DIME_UF\": dfDimeUF,\n",
    "    \"DIME_ESTADO_CIVIL\": dfDimeEstadoCivil,\n",
    "    \"DIME_COR_RACA\": dfDimeCorRaca,\n",
    "    \"DIME_NACIONALIDADE\": dfDimeNacionalidade,\n",
    "    \"DIME_SITUACAO_ESCOLARIDADE\": dfDimeSituacaoEscolaridade,\n",
    "    \"DIME_ESCOLA\": dfDimeEscola,\n",
    "    \"DIME_FAIXA_RENDA_MENSAL\": dfDimeFaixaRendaMensal,\n",
    "    \"DIME_FAIXA_ETARIA\": dfDimeFaixaEtaria\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a65a3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao realizar o commit: Cannot commit transaction: (3902, b'The COMMIT TRANSACTION request has no corresponding BEGIN TRANSACTION.DB-Lib error message 20018, severity 16:\\nGeneral SQL Server error: Check messages from the SQL Server\\n')\n",
      "Rollback realizado devido a erro no commit.\n"
     ]
    }
   ],
   "source": [
    "autocommit = conn.autocommit\n",
    "if not autocommit:\n",
    "    cursor.execute(\"BEGIN TRANSACTION\")\n",
    "try:\n",
    "    for nomeTabela,dataFrame in dicionarioDataFrames.items():\n",
    "        # Dropando a tabela se ela já existir\n",
    "        drop_table_query = f\"\"\"\n",
    "        IF OBJECT_ID(N'{nomeTabela}', 'U') IS NOT NULL\n",
    "            DROP TABLE {nomeTabela}\n",
    "        \"\"\"\n",
    "    # print(f\"DROP TABLE {nomeTabela}\")\n",
    "        try:\n",
    "            cursor.execute(drop_table_query)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao realizar o comando DROP TABLE {nomeTabela}: {e}\")\n",
    "\n",
    "    # Comitar após tentar dropar todas as tabelas\n",
    "    try:\n",
    "        conn.commit()\n",
    "        print(\"Commit realizado com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao realizar o commit: {e}\")\n",
    "        conn.rollback()\n",
    "        print(\"Rollback realizado devido a erro no commit.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao realizar as operações: {e}\")\n",
    "    if not autocommit:\n",
    "        conn.rollback()\n",
    "        print(\"Rollback realizado devido a erro nas operações.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3a9952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ColunasImportar(df):\n",
    "    dfSchema = df.schema\n",
    "    definicaoColuna = [f\"field.name] {field.dataType}\" for  field in dfSchema.fields]\n",
    "    \n",
    "    #Mapeamento de dados de acordo com os tipos de dados do SQL SERVER\n",
    "    dataMapping = {\n",
    "    IntegerType().simpleString(): \"INT\",\n",
    "    StringType().simpleString(): \"NVARCHAR(255)\",  # Você pode ajustar o tamanho conforme necessário\n",
    "    DoubleType().simpleString(): \"FLOAT\",\n",
    "    LongType().simpleString(): \"BIGINT\"\n",
    "    }\n",
    "    # Função para obter o tipo de dados SQL Server correspondente\n",
    "    def sqlTipo(data_type):\n",
    "        return dataMapping.get(data_type.simpleString(), \"NVARCHAR(255)\")  # Default para NVARCHAR(255)\n",
    "\n",
    "    #Definindo o tipo de dados das colunas de acordo com o utilizado no SQL SERVER\n",
    "    colunasParaCreate = [f\"{field.name} {sqlTipo(field.dataType)}\" for field in dfSchema.fields]\n",
    "    colunasParaInsert = [f\"{field.name}\" for field in dfSchema.fields]\n",
    "\n",
    "    #Convertendo para String\n",
    "    colunasParaCreateStr = \",\\n\".join(colunasParaCreate)\n",
    "    colunasParaInsertStr =  \",\\n\".join(colunasParaInsert)\n",
    " \n",
    "    return colunasParaCreateStr,colunasParaInsertStr\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee7dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela FATO_ENEM criada com sucesso.\n",
      "Tabela DIME_SEXO criada com sucesso.\n",
      "Tabela DIME_MUNICIPIO criada com sucesso.\n",
      "Tabela DIME_UF criada com sucesso.\n",
      "Tabela DIME_ESTADO_CIVIL criada com sucesso.\n",
      "Tabela DIME_COR_RACA criada com sucesso.\n",
      "Tabela DIME_NACIONALIDADE criada com sucesso.\n",
      "Tabela DIME_SITUACAO_ESCOLARIDADE criada com sucesso.\n",
      "Tabela DIME_ESCOLA criada com sucesso.\n",
      "Tabela DIME_FAIXA_RENDA_MENSAL criada com sucesso.\n",
      "Tabela DIME_FAIXA_ETARIA criada com sucesso.\n",
      "Commit realizado com sucesso.\n"
     ]
    }
   ],
   "source": [
    "#autocommit = conn.autocommit\n",
    "if not autocommit:\n",
    "    cursor.execute(\"BEGIN TRANSACTION\")\n",
    "\n",
    "try:   \n",
    "    for nomeTabela,dataFrame in dicionarioDataFrames.items():\n",
    "        colunaCreate, colunaInsert_ = ColunasImportar(dataFrame)\n",
    "        create_table_query = f\"\"\"\n",
    "        CREATE TABLE {nomeTabela} (\n",
    "        {colunaCreate}\n",
    "        )\n",
    "        \"\"\"\n",
    "        #print(create_table_query)\n",
    "        # Executando o comando SQL para criar a tabela\n",
    "        try:\n",
    "            cursor.execute(create_table_query)\n",
    "            print(f\"Tabela {nomeTabela} criada com sucesso.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao criar a tabela {nomeTabela}: {e}\")\n",
    "    # Comitr após tentar criar todas as tabelas\n",
    "    #if  autocommit:\n",
    "    conn.commit()\n",
    "    print(\"Commit realizado com sucesso.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao realizar as operações: {e}\")\n",
    "    if not autocommit:\n",
    "        conn.rollback()\n",
    "        print(\"Rollback realizado devido a erro nas operações.\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbc84db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(data, chunk_size):\n",
    "    \"\"\"Divide a data list em pedaços de tamanho chunk_size.\"\"\"\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        yield data[i:i + chunk_size]\n",
    "\n",
    "def insert(query, data, chunk=999):\n",
    "    query = query.lower()\n",
    "    insert_q, values_q = query.split('values')\n",
    "    insert_q += 'values'  # Adiciona 'values' para manter a query SQL correta após o split\n",
    "\n",
    "    try:\n",
    "        for chunk_data in chunks(data, chunk):\n",
    "            flat_list = [item for sublist in chunk_data for item in sublist]\n",
    "            chunk_query = insert_q + ','.join([values_q] * len(chunk_data))\n",
    "            cursor.execute(chunk_query, tuple(flat_list))\n",
    "            conn.commit()  # Comitar após cada chunk\n",
    "    except pymssql.OperationalError as e:\n",
    "        print(f\"OperationalError: {e}\")\n",
    "        conn.rollback()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461a7dfd-e5af-4cca-a07f-0a124d0c882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "autocommit = conn.autocommit\n",
    "if not autocommit:\n",
    "    cursor.execute(\"BEGIN TRANSACTION\")\n",
    "try:\n",
    "    for nomeTabela,dataFrame in dicionarioDataFrames.items():\n",
    "        colunaCreate, colunaInsert_ = ColunasImportar(dataFrame)\n",
    "        #Converter em lista para a função LEN retornar a quantidade de objetos\n",
    "        colunaInsertList = colunaInsert_.split(',')\n",
    "        rows = dataFrame.collect()\n",
    "        #converte a lista rows em uma tupla para utilizar no insert\n",
    "        dadosInsert = tuple(map(tuple, rows))\n",
    "\n",
    "        query = f\"\"\"\n",
    "            INSERT INTO {nomeTabela} ({colunaInsert_})\n",
    "            VALUES ({', '.join(['%s'] * len(colunaInsertList))})\n",
    "        \n",
    "        \"\"\"\n",
    "        #função que faz o insert no sql em bloco\n",
    "        insert(query, dadosInsert)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao realizar as operações: {e}\")\n",
    "    if not autocommit:\n",
    "        conn.rollback()\n",
    "        print(\"Rollback realizado devido a erro nas operações.\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15925b32",
   "metadata": {},
   "source": [
    "## CRIAR VIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c5da13",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewFatoEnem = (\"\"\"\n",
    "                                       \n",
    "    CREATE VIEW vwFatoEnem AS(\n",
    "        SELECT \n",
    "        F.ANO_EDICAO,\n",
    "        F.ANO_CONCLUSAO,\n",
    "        E.ESCOLA_DESCRICAO,\n",
    "        EC.ESTADO_CIVIL_DESCRICAO,\n",
    "        FE.FAIXA_ETARIA_DESCRICAO,\n",
    "        FRM.FAIXA_RENDA_MENSAL_DESCRICAO,\n",
    "        M.MUNICIPIO_DESCRICAO,\n",
    "        U.UF_SIGLA,                \n",
    "        U.UF_DESCRICAO,\n",
    "        N.NACIONALIDADE_DESCRICAO,\n",
    "        S.SEXO_DESCRICAO,\n",
    "        SE.SITUACAO_ESCOLARIDADE_DESCRICAO,\n",
    "        QTD AS QTD_INSCRITOS,\n",
    "        NOTA_CIENCIA_DA_NATUREZA,\n",
    "        NOTA_CIENCIA_DA_HUMANA,\n",
    "        NOTA_LINGUAGEM_CODIGO,\n",
    "        NOTA_MATEMATICA\n",
    "\n",
    "        FROM FATO_ENEM F\n",
    "        INNER JOIN DIME_COR_RACA CR\n",
    "        ON F.COR_RACA_ID = CR.COR_RACA_ID\n",
    "        INNER JOIN DIME_ESCOLA E\n",
    "        ON F.ESCOLA_ID= E.ESCOLA_ID\n",
    "        INNER JOIN DIME_ESTADO_CIVIL EC\n",
    "        ON F.ESTADO_CIVIL_ID = EC.ESTADO_CIVIL_ID\n",
    "        INNER JOIN DIME_FAIXA_ETARIA FE\n",
    "        ON F.FAIXA_ETARIA_ID = FE.FAIXA_ETARIA_ID\n",
    "        INNER JOIN DIME_FAIXA_RENDA_MENSAL FRM\n",
    "        ON F.FAIXA_RENDA_MENSAL_ID = FRM.FAIXA_RENDA_MENSAL_ID\n",
    "        INNER JOIN DIME_MUNICIPIO M \n",
    "        ON F.MUNICIPIO_ID = M.MUNICIPIO_ID\n",
    "        INNER JOIN DIME_UF U\n",
    "        ON M.UF_ID = U.UF_ID\n",
    "        INNER JOIN DIME_NACIONALIDADE N\n",
    "        ON F.NACIONALIDADE_ID = N.NACIONALIDADE_ID\n",
    "        INNER JOIN DIME_SEXO S\n",
    "        ON F.SEXO_ID = S.SEXO_ID\n",
    "        INNER JOIN DIME_SITUACAO_ESCOLARIDADE SE\n",
    "        ON F.SITUACAO_ESCOLARIDADE_ID = SE.SITUACAO_ESCOLARIDADE_ID\n",
    "        )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b29e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "     cursor.execute(\"\"\"DROP VIEW vwFatoEnem\n",
    "            \"\"\")\n",
    "     try: \n",
    "         cursor.execute(viewFatoEnem)\n",
    "\n",
    "     except Exception as e:\n",
    "          print(f\"Erro ao realizar as operações: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao realizar as operações: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c30838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fechando cursor e conexão\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
