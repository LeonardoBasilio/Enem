{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "339b1583-ef73-40a5-9735-354b42f393b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importação das Bibiliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc20c5a9-44d0-4ee3-ac2c-0f588099a1c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from pyspark.sql.functions import col, count, sum\n",
    "import pymssql\n",
    "#import pyodbc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92050d4",
   "metadata": {},
   "source": [
    "## Criando uma SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "137c301b-7b56-434b-bd08-979c6717af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando a Imagem Docker\n",
    "#spark = SparkSession.builder.remote(\"sc://spark-connect\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d05b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie um SparkSession\n",
    "spark = SparkSession.builder.appName(\"LerDadosEnem\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8ed9e6-77de-42fb-96ed-d1b23d0251a4",
   "metadata": {},
   "source": [
    "## Processo de Leitura do CSV de Participantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c848f5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path dos arquivos usando Imagem do docker\n",
    "\n",
    "#caminho_arquivo_2022 = '/opt/datasets/ENEM/2022/microdados_enem_2022/DADOS/MICRODADOS_ENEM_2022.csv'\n",
    "#caminho_arquivo_2021 = '/opt/datasets/ENEM/2021/microdados_enem_2021/DADOS/MICRODADOS_ENEM_2021.csv'\n",
    "#caminho_arquivo_2020 = '/opt/datasets/ENEM/2020/microdados_enem_2020/DADOS/MICRODADOS_ENEM_2020.csv'\n",
    "#caminho_arquivo_2019 = '/opt/datasets/ENEM/2019/microdados_enem_2019/DADOS/MICRODADOS_ENEM_2019.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce135fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path dos arquivos\n",
    "\n",
    "caminho_arquivo_2022 = r'E:\\Estudos\\SQL\\Datasets\\ENEM\\2022\\microdados_enem_2022\\DADOS\\MICRODADOS_ENEM_2022.csv'\n",
    "caminho_arquivo_2021 = r'E:\\Estudos\\SQL\\Datasets\\ENEM\\2021\\microdados_enem_2021\\DADOS\\MICRODADOS_ENEM_2021.csv'\n",
    "caminho_arquivo_2020 = r'E:\\Estudos\\SQL\\Datasets\\ENEM\\2020\\microdados_enem_2020\\DADOS\\MICRODADOS_ENEM_2020.csv'\n",
    "caminho_arquivo_2019 = r'E:\\Estudos\\SQL\\Datasets\\ENEM\\2019\\microdados_enem_2019\\DADOS\\MICRODADOS_ENEM_2019.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04836a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função Paa ler os arquivos CSV\n",
    "def lerCSV(spark, caminho_arquivo):\n",
    "    df = spark.read.csv(caminho_arquivo, sep=';', header=True, inferSchema=True, encoding='ISO-8859-1')\n",
    "    #colunas_selecionadas = df.columns[12:19]\n",
    "    #return df.select(colunas_selecionadas)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "158e76e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Chama função quer ler o arquivo CSV e Transforma para DF.SPARK\n",
    "\n",
    "dfEscola22 = lerCSV(spark, caminho_arquivo_2022)\n",
    "#dfEscola21 = lerCSV(spark, caminho_arquivo_2021)\n",
    "#dfEscola20 = lerCSV(spark, caminho_arquivo_2020)\n",
    "#dfEscola19 = lerCSV(spark, caminho_arquivo_2019)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "579583cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unir os DF em um só \n",
    "\n",
    "#dfDadosGerais = dfEscola22.union(dfEscola21).union(dfEscola20).union(dfEscola19)\n",
    "dfDadosGerais = dfEscola22\n",
    "#dfDadosGerais = dfDadosGerais.limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0ddb3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPreencher = dfDadosGerais.fillna(-2)  # Preenche com -2(sem ref), por exemplo\n",
    "#dfPreencher.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b839ff03-3177-4106-9812-c704694c2b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPreencherDistinct = dfPreencher.select(\n",
    "    col(\"NU_INSCRICAO\").alias(\"NU_INSCRICAO\"),\n",
    "    col(\"NU_ANO\").alias(\"ANO_EDICAO\"),\n",
    "    col(\"TP_ANO_CONCLUIU\").alias(\"ANO_CONCLUSAO\"),\n",
    "    col(\"TP_SEXO\").alias(\"SEXO_CODIGO\"),\n",
    "    col(\"CO_MUNICIPIO_ESC\").alias(\"MUNICIPIO_CODIGO\"),\n",
    "    col(\"TP_ESTADO_CIVIL\").alias(\"ESTADO_CIVIL_ID\"),\n",
    "    col(\"TP_COR_RACA\").alias(\"COR_RACA_ID\"),\n",
    "    col(\"TP_NACIONALIDADE\").alias(\"NACIONALIDADE_ID\"),\n",
    "    col(\"TP_ST_CONCLUSAO\").alias(\"SITUACAO_ESCOLARIDADE_ID\"),\n",
    "    col(\"TP_ESCOLA\").alias(\"ESCOLA_ID\"),\n",
    "    col(\"Q006\").alias(\"FAIXA_RENDA_MENSAL_ID\"),\n",
    "    col(\"TP_FAIXA_ETARIA\").alias(\"FAIXA_ETARIA_ID\"),\n",
    "    col(\"NU_NOTA_CN\").alias(\"NOTA_CIENCIA_DA_NATUREZA\"),\n",
    "    col(\"NU_NOTA_CH\").alias(\"NOTA_CIENCIA_DA_HUMANA\"),\n",
    "    col(\"NU_NOTA_LC\").alias(\"NOTA_LINGUAGEM_CODIGO\"),\n",
    "    col(\"NU_NOTA_MT\").alias(\"NOTA_MATEMATICA\")\n",
    ").distinct()\n",
    "#dfPreencherDistinct.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06fe582-dbdc-439b-be2c-707748b304a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dfPreencherDistinct.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a8852d0-721d-41a7-a6f9-366cd5d2c6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ANO_EDICAO: int, ANO_CONCLUSAO: int, SEXO_CODIGO: string, MUNICIPIO_CODIGO: int, ESTADO_CIVIL_ID: int, COR_RACA_ID: int, NACIONALIDADE_ID: int, SITUACAO_ESCOLARIDADE_ID: int, ESCOLA_ID: int, FAIXA_RENDA_MENSAL_ID: string, FAIXA_ETARIA_ID: int, QTD: bigint, NOTA_CIENCIA_DA_NATUREZA: double, NOTA_CIENCIA_DA_HUMANA: double, NOTA_LINGUAGEM_CODIGO: double, NOTA_MATEMATICA: double]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAgregate = dfPreencherDistinct.select(\n",
    "    \"ANO_EDICAO\",\n",
    "    \"ANO_CONCLUSAO\",\n",
    "    \"SEXO_CODIGO\",\n",
    "    \"MUNICIPIO_CODIGO\",\n",
    "    \"ESTADO_CIVIL_ID\",\n",
    "    \"COR_RACA_ID\",\n",
    "    \"NACIONALIDADE_ID\",\n",
    "    \"SITUACAO_ESCOLARIDADE_ID\",\n",
    "    \"ESCOLA_ID\",\n",
    "    \"FAIXA_RENDA_MENSAL_ID\",\n",
    "    \"FAIXA_ETARIA_ID\",\n",
    "    \"NU_INSCRICAO\",  # Adicionando essa coluna para o count\n",
    "    \"NOTA_CIENCIA_DA_NATUREZA\",\n",
    "    \"NOTA_CIENCIA_DA_HUMANA\",\n",
    "    \"NOTA_LINGUAGEM_CODIGO\",\n",
    "    \"NOTA_MATEMATICA\"\n",
    ")\n",
    "\n",
    "# Agregação após o agrupamento\n",
    "dfAgregate = dfAgregate.groupBy(\n",
    "    \"ANO_EDICAO\",\n",
    "    \"ANO_CONCLUSAO\",\n",
    "    \"SEXO_CODIGO\",\n",
    "    \"MUNICIPIO_CODIGO\",\n",
    "    \"ESTADO_CIVIL_ID\",\n",
    "    \"COR_RACA_ID\",\n",
    "    \"NACIONALIDADE_ID\",\n",
    "    \"SITUACAO_ESCOLARIDADE_ID\",\n",
    "    \"ESCOLA_ID\",\n",
    "    \"FAIXA_RENDA_MENSAL_ID\",\n",
    "    \"FAIXA_ETARIA_ID\"\n",
    ").agg(\n",
    "    count(\"NU_INSCRICAO\").alias(\"QTD\"),\n",
    "    sum(\"NOTA_CIENCIA_DA_NATUREZA\").alias(\"NOTA_CIENCIA_DA_NATUREZA\"),\n",
    "    sum(\"NOTA_CIENCIA_DA_HUMANA\").alias(\"NOTA_CIENCIA_DA_HUMANA\"),\n",
    "    sum(\"NOTA_LINGUAGEM_CODIGO\").alias(\"NOTA_LINGUAGEM_CODIGO\"),\n",
    "    sum(\"NOTA_MATEMATICA\").alias(\"NOTA_MATEMATICA\")\n",
    ")\n",
    "\n",
    "dfAgregate.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fc1c05e-073b-4a3d-beeb-7ef9eb6b2f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('ANO_EDICAO', IntegerType(), True), StructField('ANO_CONCLUSAO', IntegerType(), True), StructField('SEXO_CODIGO', StringType(), True), StructField('MUNICIPIO_CODIGO', IntegerType(), True), StructField('ESTADO_CIVIL_ID', IntegerType(), True), StructField('COR_RACA_ID', IntegerType(), True), StructField('NACIONALIDADE_ID', IntegerType(), True), StructField('SITUACAO_ESCOLARIDADE_ID', IntegerType(), True), StructField('ESCOLA_ID', IntegerType(), True), StructField('FAIXA_RENDA_MENSAL_ID', StringType(), True), StructField('FAIXA_ETARIA_ID', IntegerType(), True), StructField('QTD', LongType(), False), StructField('NOTA_CIENCIA_DA_NATUREZA', DoubleType(), True), StructField('NOTA_CIENCIA_DA_HUMANA', DoubleType(), True), StructField('NOTA_LINGUAGEM_CODIGO', DoubleType(), True), StructField('NOTA_MATEMATICA', DoubleType(), True)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAgregate.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9fbdb3-fa7c-4592-8d43-42d0553f75e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pandas = dfAgregate.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ed5ca",
   "metadata": {},
   "source": [
    "# Salvar em SQL \n",
    "Salvar os dados em uma tabela SQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1deb1f",
   "metadata": {},
   "source": [
    "## Parametrizando a conexão do Banco SQL SERVER Usando JDBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9e7396db",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_name = \"localhost\"\n",
    "database_name = \"DockerEnem\"\n",
    "username = \"sa\"\n",
    "password = \"bi@123456\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "45262d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectando ao banco de dados\n",
    "conn = pymssql.connect(server=server_name, database=database_name, user=username, password=password,port='1434')\n",
    "# Criando um cursor\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d3234ec7-5988-465d-83b4-e623266a33e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nome da tabela a ser excluída\n",
    "table_name = \"ODS_ENEM\"\n",
    "\n",
    "#obter Schema do dfAgregate \n",
    "df_schema = dfAgregate.schema\n",
    "\n",
    "# Gerando as definições de coluna para a tabela\n",
    "columns_definitions = [f\"{field.name} {field.dataType}\" for field in df_schema.fields]\n",
    "\n",
    "# Mapeamento de tipos de dados do Spark para tipos de dados do SQL Server\n",
    "data_type_mapping = {\n",
    "    \"IntegerType\": \"INT\",\n",
    "    \"StringType\": \"NVARCHAR(255)\",  # Você pode ajustar o tamanho conforme necessário\n",
    "    \"DoubleType\": \"FLOAT\",\n",
    "    \"LongType\": \"BIGINT\"\n",
    "}\n",
    "\n",
    "# Gerando as definições de coluna para a tabela com os tipos de dados corretos\n",
    "columns_definitions = [f\"{field.name} {data_type_mapping.get(str(field.dataType), 'NVARCHAR(255)')}\" for field in df_schema.fields]\n",
    "columns_update = [f\"{field.name}\" for field in df_schema.fields]\n",
    "\n",
    "\n",
    "# Combinando as definições de coluna em uma string\n",
    "columns_str = \",\\n\".join(columns_definitions)\n",
    "columns_update_str =  \",\\n\".join(columns_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f3a8e0f-907e-4a25-aee7-793eac934db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dropando a tabela se ela já existir\n",
    "drop_table_query = \"\"\"\n",
    "IF OBJECT_ID('ODS_ENEM', 'U') IS NOT NULL\n",
    "    DROP TABLE ODS_ENEM\n",
    "\"\"\"\n",
    "cursor.execute(drop_table_query)\n",
    "conn.commit()  # Comitar após dropar a tabela\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cd02afb5-f05e-4c46-aa3c-c612bdef245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o comando CREATE TABLE\n",
    "create_table_query = f\"\"\"\n",
    "CREATE TABLE {table_name} (\n",
    "{columns_str}\n",
    ")\n",
    "\"\"\"\n",
    "# Executando o comando SQL para criar a tabela\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()  # Comitar após criar a tabela\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "461a7dfd-e5af-4cca-a07f-0a124d0c882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = dfAgregate.collect()\n",
    "#print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572fb0c-ada9-4956-a48f-92574aec63b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_query = f\"\"\"\n",
    "    INSERT INTO ODS_ENEM ({columsn_update})\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\"\"\n",
    "write_data = tuple(map(tuple, rows))\n",
    "cursor.executemany(insert_query, write_data)\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6fbc84db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(data, chunk_size):\n",
    "    \"\"\"Divide a data list em pedaços de tamanho chunk_size.\"\"\"\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        yield data[i:i + chunk_size]\n",
    "\n",
    "def insert(query, data, chunk=999):\n",
    "    query = query.lower()\n",
    "    insert_q, values_q = query.split('values')\n",
    "    insert_q += 'values'  # Adiciona 'values' para manter a query SQL correta após o split\n",
    "\n",
    "    try:\n",
    "        for chunk_data in chunks(data, chunk):\n",
    "            flat_list = [item for sublist in chunk_data for item in sublist]\n",
    "            chunk_query = insert_q + ','.join([values_q] * len(chunk_data))\n",
    "            cursor.execute(chunk_query, tuple(flat_list))\n",
    "            conn.commit()  # Comitar após cada chunk\n",
    "    except pymssql.OperationalError as e:\n",
    "        print(f\"OperationalError: {e}\")\n",
    "        conn.rollback()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eceedb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a query de inserção\n",
    "insert_query = f\"\"\"\n",
    "    INSERT INTO {table_name} ({columns_update_str})\n",
    "    VALUES ({', '.join(['%s'] * len(df_schema.fields))})\n",
    "\"\"\"\n",
    "# Convertendo os dados para tuplas\n",
    "write_data = [tuple(row) for row in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8204e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "insert(insert_query, write_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "02c30838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fechando cursor e conexão\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
